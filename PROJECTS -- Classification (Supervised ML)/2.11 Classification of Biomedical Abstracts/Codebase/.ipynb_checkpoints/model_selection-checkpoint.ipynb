{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RepeatedKFold, StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score as kappa, confusion_matrix, roc_auc_score, roc_curve, f1_score, make_scorer\n",
    "\n",
    "from helpers import PICKLE_DIR, pickle_object\n",
    "import pandas as pd\n",
    "\n",
    "def nb_classifier():\n",
    "    skf = StratifiedKFold(4)\n",
    "    gnb = GaussianNB()\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        gnb.fit(X_train, y_train)\n",
    "        y_pred = gnb.predict(X_test)\n",
    "        score = gnb.score(X_test, y_test)\n",
    "\n",
    "        print('Score: {}'.format(score))\n",
    "        print('Classification report for fold {}:'.format(i))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print('\\n---\\n')\n",
    "\n",
    "\n",
    "    X_test_final = pd.read_pickle(PICKLE_DIR / 'testing_X_lsa_6000_components.gz', 'gzip')\n",
    "    y_test_final = pd.read_pickle(PICKLE_DIR / 'testing_labels.gz', 'gzip')\n",
    "    # y_test_final = binarizer.transform(y_test_final)\n",
    "    y_pred_final = gnb.predict(X_test_final)\n",
    "\n",
    "    score = gnb.score(X_test_final, y_test_final)\n",
    "    print('Score: {}'.format(score))\n",
    "\n",
    "    print('Final Classification Report:')\n",
    "    print(classification_report(y_test_final, y_pred_final))\n",
    "    return\n",
    "\n",
    "#############################################################\n",
    "\n",
    "#######SVM classifier ###########\n",
    "\n",
    "def svm_clf():\n",
    "\n",
    "    skf = StratifiedKFold(4)\n",
    "    svm = SVC(kernel= 'rbf', gamma= 1e-2, C= 0.001)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        score = svm.score(X_test, y_test)\n",
    "\n",
    "        print('Score: {}'.format(score))\n",
    "        print('Classification report for fold {}:'.format(i))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print('\\n---\\n')\n",
    "\n",
    "\n",
    "    X_test_final = pd.read_pickle(PICKLE_DIR / 'testing_X_lsa_6000_components.gz', 'gzip')\n",
    "    y_test_final = pd.read_pickle(PICKLE_DIR / 'testing_labels.gz', 'gzip')\n",
    "    y_pred_final = svm.predict(X_test_final)\n",
    "\n",
    "    score = svm.score(X_test_final, y_test_final)\n",
    "    print('Score: {}'.format(score))\n",
    "\n",
    "    print('Final Classification Report:')\n",
    "    print(classification_report(y_test_final, y_pred_final))\n",
    "    return\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def svm_clf_2():\n",
    "\n",
    "        tuned_parameters =  [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                             'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]},\n",
    "                            {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                             'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000] },\n",
    "                             {'kernel': ['linear'], 'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]},\n",
    "                            {'kernel': ['poly'], 'degree': [2, 3, 4, 5, 6, 7, 8]} ]              \n",
    "\n",
    "        custom_scorer = make_scorer(f1_score, greater_is_better=True)\n",
    "        clf = GridSearchCV(SVC(), tuned_parameters, cv=10, scoring=custom_scorer)\n",
    "        clf.fit(X, y)\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print('Training F1_score')\n",
    "        print(clf.best_score_)\n",
    "        print(clf.best_estimator_)\n",
    "        print()\n",
    "        print('****Results on Test Dataset****')\n",
    "        X_test_final = pd.read_pickle(PICKLE_DIR / 'testing_X_lsa_6000_components.gz', 'gzip')\n",
    "        y_test_final = pd.read_pickle(PICKLE_DIR / 'testing_labels.gz', 'gzip')\n",
    "        svm_pred=clf.predict(X_test_final)\n",
    "        score = clf.score(X_test_final, y_test_final)\n",
    "\n",
    "#############################################################\n",
    "\n",
    "def RandomForest(X, y, n_estimators, max_depth, random_state, criterion, max_features =\"auto\"):\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)  \n",
    "   \n",
    "    skf = StratifiedKFold(4)\n",
    "    #svm = SVC(kernel= 'rbf', gamma= 1e-2, C= 0.001)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Fitting Random Forest Classifier to the Training set\n",
    "        rf = RandomForestClassifier(n_estimators = n_estimators, max_depth=max_depth, max_features=max_features, random_state=random_state, criterion = criterion)\n",
    "        rf.fit(X, y)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        score = rf.score(X_test, y_test)\n",
    "\n",
    "        print('Score: {}'.format(score))\n",
    "        print('Classification report for fold {}:'.format(i))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print('\\n---\\n')\n",
    "\n",
    "\n",
    "    X_test_final = pd.read_pickle(PICKLE_DIR / 'testing_X_lsa_6000_components.gz', 'gzip')\n",
    "    y_test_final = pd.read_pickle(PICKLE_DIR / 'testing_labels.gz', 'gzip')\n",
    "    # y_test_final = binarizer.transform(y_test_final)\n",
    "    y_pred_final = rf.predict(X_test_final)\n",
    "\n",
    "    score = svm.score(X_test_final, y_test_final)\n",
    "    print('Score: {}'.format(score))\n",
    "\n",
    "    print('Final Classification Report:')\n",
    "    print(classification_report(y_test_final, y_pred_final))\n",
    "\n",
    "#############################################################\n",
    "def ensemble_method():\n",
    "    \n",
    "    model_1 = GaussianNB()\n",
    "    \n",
    "    model_2 = RandomForestClassifier(n_estimators = 100, max_depth=25, max_features=20, random_state=0, criterion = 'entropy')\n",
    "    \n",
    "    model_3 = SVC(kernel= 'rbf', gamma= 1e-2, C= 0.001)\n",
    "    \n",
    "    model = VotingClassifier(estimators=[('nb', model_1), ('rf', model_2), ('svc', model_3)], voting='hard')\n",
    "    \n",
    "    model.fit(X,y)\n",
    "    model.score(x_test,y_test)\n",
    "    \n",
    "    X_test_final = pd.read_pickle(PICKLE_DIR / 'testing_X_lsa_10000_feat_5000_comp.gz', 'gzip')\n",
    "    y_test_final = pd.read_pickle(PICKLE_DIR / 'testing_labels_.gz', 'gzip')\n",
    "    # y_test_final = binarizer.transform(y_test_final)\n",
    "    #y_pred_final = model.predict(X_test_final)\n",
    "    print(model.score(X_test_final,y_test_final))\n",
    "\n",
    "#############################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    binarizer = LabelBinarizer()\n",
    "        \n",
    "    X = pd.read_pickle(PICKLE_DIR / 'training_X_lsa_10000_feat_5000_comp.gz', 'gzip')\n",
    "    y = pd.read_pickle(PICKLE_DIR / 'training_labels_.gz', 'gzip')\n",
    "    # y = binarizer.fit_transform(y)\n",
    "    \n",
    "    #nb_classifier()\n",
    "    #svm_clf()\n",
    "    #svm_clf_2()\n",
    "    #RandomForest(X, y, n_estimators = 100, max_depth=25, max_features=20, random_state=0, criterion = 'entropy')\n",
    "    ensemble_method()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
