{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batchnorm_TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt2sTLLd5dmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Lazy courses/DS:Deep Learning in Python/NN -Fundamental concepts from scratch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV_yhdbk5SEw",
        "colab_type": "code",
        "outputId": "5e512882-063c-4aeb-f338-ca0046f88336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from util import get_normalized_data\n",
        "\n",
        "\n",
        "def init_weight(M1, M2):\n",
        "  return np.random.randn(M1, M2) * np.sqrt(2.0 / M1)\n",
        "\n",
        "\n",
        "class HiddenLayerBatchNorm(object):\n",
        "  def __init__(self, M1, M2, f):\n",
        "    self.M1 = M1\n",
        "    self.M2 = M2\n",
        "    self.f = f\n",
        "\n",
        "    W = init_weight(M1, M2).astype(np.float32)\n",
        "    gamma = np.ones(M2).astype(np.float32)\n",
        "    beta = np.zeros(M2).astype(np.float32)\n",
        "\n",
        "    self.W = tf.Variable(W)\n",
        "    self.gamma = tf.Variable(gamma)\n",
        "    self.beta = tf.Variable(beta)\n",
        "\n",
        "    # for test time\n",
        "    self.running_mean = tf.Variable(np.zeros(M2).astype(np.float32), trainable=False)\n",
        "    self.running_var = tf.Variable(np.zeros(M2).astype(np.float32), trainable=False)\n",
        "\n",
        "  def forward(self, X, is_training, decay=0.9):\n",
        "    activation = tf.matmul(X, self.W)\n",
        "    if is_training:\n",
        "      batch_mean, batch_var = tf.nn.moments(activation, [0])\n",
        "      update_running_mean = tf.assign(\n",
        "        self.running_mean,\n",
        "        self.running_mean * decay + batch_mean * (1 - decay)\n",
        "      )\n",
        "      update_running_var = tf.assign(\n",
        "        self.running_var,\n",
        "        self.running_var * decay + batch_var * (1 - decay)\n",
        "      )\n",
        "      \n",
        "      with tf.control_dependencies([update_running_mean, update_running_var]):\n",
        "        out = tf.nn.batch_normalization(\n",
        "          activation,\n",
        "          batch_mean,\n",
        "          batch_var,\n",
        "          self.beta,\n",
        "          self.gamma,\n",
        "          1e-4\n",
        "        )\n",
        "    else:\n",
        "      out = tf.nn.batch_normalization(\n",
        "        activation,\n",
        "        self.running_mean,\n",
        "        self.running_var,\n",
        "        self.beta,\n",
        "        self.gamma,\n",
        "        1e-4\n",
        "      )\n",
        "    return self.f(out)\n",
        "\n",
        "\n",
        "class HiddenLayer(object):\n",
        "  def __init__(self, M1, M2, f):\n",
        "    self.M1 = M1\n",
        "    self.M2 = M2\n",
        "    self.f = f\n",
        "    W = np.random.randn(M1, M2) * np.sqrt(2.0 / M1)\n",
        "    b = np.zeros(M2)\n",
        "    self.W = tf.Variable(W.astype(np.float32))\n",
        "    self.b = tf.Variable(b.astype(np.float32))\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.f(tf.matmul(X, self.W) + self.b)\n",
        "\n",
        "\n",
        "class ANN(object):\n",
        "  def __init__(self, hidden_layer_sizes):\n",
        "    self.hidden_layer_sizes = hidden_layer_sizes\n",
        "\n",
        "  def set_session(self, session):\n",
        "    self.session = session\n",
        "\n",
        "  def fit(self, X, Y, Xtest, Ytest, activation=tf.nn.relu, learning_rate=1e-2, epochs=15, batch_sz=100, print_period=100, show_fig=True):\n",
        "    X = X.astype(np.float32)\n",
        "    Y = Y.astype(np.int32)\n",
        "\n",
        "    # initialize hidden layers\n",
        "    N, D = X.shape\n",
        "    self.layers = []\n",
        "    M1 = D\n",
        "    for M2 in self.hidden_layer_sizes:\n",
        "      h = HiddenLayerBatchNorm(M1, M2, activation)\n",
        "      self.layers.append(h)\n",
        "      M1 = M2\n",
        "      \n",
        "    # final layer\n",
        "    K = len(set(Y))\n",
        "    h = HiddenLayer(M1, K, lambda x: x)\n",
        "    self.layers.append(h)\n",
        "\n",
        "    if batch_sz is None:\n",
        "      batch_sz = N\n",
        "\n",
        "\n",
        "    # note! we will need to build the output differently\n",
        "    # for train and test (prediction)\n",
        "\n",
        "    # set up theano functions and variables\n",
        "    tfX = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
        "    tfY = tf.placeholder(tf.int32, shape=(None,), name='Y')\n",
        "\n",
        "    # for later use\n",
        "    self.tfX = tfX\n",
        "\n",
        "    # for training\n",
        "    logits = self.forward(tfX, is_training=True)\n",
        "    cost = tf.reduce_mean(\n",
        "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        logits=logits,\n",
        "        labels=tfY\n",
        "      )\n",
        "    )\n",
        "    # train_op = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "    # train_op = tf.train.RMSPropOptimizer(learning_rate, decay=0.99, momentum=0.9).minimize(cost)\n",
        "    train_op = tf.train.MomentumOptimizer(learning_rate, momentum=0.9, use_nesterov=True).minimize(cost)\n",
        "    # train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "    # for testing\n",
        "    test_logits = self.forward(tfX, is_training=False)\n",
        "    self.predict_op = tf.argmax(test_logits, 1)\n",
        "\n",
        "    # accuracy = tf.reduce_mean(1.0*(tfY == tf.argmax(logits, 1)))\n",
        "\n",
        "    # init the variables\n",
        "    self.session.run(tf.global_variables_initializer())\n",
        "\n",
        "    n_batches = N // batch_sz\n",
        "    costs = []\n",
        "    for i in range(epochs):\n",
        "      if n_batches > 1:\n",
        "        X, Y = shuffle(X, Y)\n",
        "      for j in range(n_batches):\n",
        "        Xbatch = X[j*batch_sz:(j*batch_sz+batch_sz)]\n",
        "        Ybatch = Y[j*batch_sz:(j*batch_sz+batch_sz)]\n",
        "\n",
        "        c, _, lgts = self.session.run([cost, train_op, logits], feed_dict={tfX: Xbatch, tfY: Ybatch})\n",
        "        costs.append(c)\n",
        "        if (j+1) % print_period == 0:\n",
        "          acc = np.mean(Ybatch == np.argmax(lgts, axis=1))\n",
        "          print(\"epoch:\", i, \"batch:\", j, \"n_batches:\", n_batches, \"cost:\", c, \"acc: %.2f\" % acc)\n",
        "          # print('dbg:', self.session.run(self.layers[0].running_mean).sum())\n",
        "\n",
        "      print(\"Train acc:\", self.score(X, Y), \"Test acc:\", self.score(Xtest, Ytest))\n",
        "    \n",
        "    if show_fig:\n",
        "      plt.plot(costs)\n",
        "      plt.show()\n",
        "\n",
        "  def forward(self, X, is_training):\n",
        "    out = X\n",
        "    for h in self.layers[:-1]:\n",
        "      out = h.forward(out, is_training)\n",
        "    out = self.layers[-1].forward(out)\n",
        "    return out\n",
        "\n",
        "  def score(self, X, Y):\n",
        "    P = self.predict(X)\n",
        "    return np.mean(Y == P)\n",
        "\n",
        "  def predict(self, X):\n",
        "    return self.session.run(self.predict_op, feed_dict={self.tfX: X})\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "  # step 1: get the data and define all the usual variables\n",
        "  Xtrain, Xtest, Ytrain, Ytest = get_normalized_data()\n",
        "\n",
        "  ann = ANN([500, 300])\n",
        "\n",
        "  session = tf.InteractiveSession()\n",
        "  ann.set_session(session)\n",
        "\n",
        "  ann.fit(Xtrain, Ytrain, Xtest, Ytest, show_fig=True)\n",
        "\n",
        "  print(\"Train accuracy:\", ann.score(Xtrain, Ytrain))\n",
        "  print(\"Test accuracy:\", ann.score(Xtest, Ytest))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading in and transforming data...\n",
            "epoch: 0 batch: 99 n_batches: 410 cost: 0.43024883 acc: 0.89\n",
            "epoch: 0 batch: 199 n_batches: 410 cost: 0.23559822 acc: 0.90\n",
            "epoch: 0 batch: 299 n_batches: 410 cost: 0.25774443 acc: 0.90\n",
            "epoch: 0 batch: 399 n_batches: 410 cost: 0.13450411 acc: 0.97\n",
            "Train acc: 0.9607317073170731 Test acc: 0.945\n",
            "epoch: 1 batch: 99 n_batches: 410 cost: 0.11736947 acc: 0.96\n",
            "epoch: 1 batch: 199 n_batches: 410 cost: 0.1733123 acc: 0.94\n",
            "epoch: 1 batch: 299 n_batches: 410 cost: 0.30695155 acc: 0.93\n",
            "epoch: 1 batch: 399 n_batches: 410 cost: 0.15359253 acc: 0.95\n",
            "Train acc: 0.9769756097560975 Test acc: 0.951\n",
            "epoch: 2 batch: 99 n_batches: 410 cost: 0.10841472 acc: 0.98\n",
            "epoch: 2 batch: 199 n_batches: 410 cost: 0.07769207 acc: 0.97\n",
            "epoch: 2 batch: 299 n_batches: 410 cost: 0.05800082 acc: 0.98\n",
            "epoch: 2 batch: 399 n_batches: 410 cost: 0.11783369 acc: 0.96\n",
            "Train acc: 0.9869512195121951 Test acc: 0.964\n",
            "epoch: 3 batch: 99 n_batches: 410 cost: 0.050804358 acc: 0.99\n",
            "epoch: 3 batch: 199 n_batches: 410 cost: 0.06368112 acc: 0.98\n",
            "epoch: 3 batch: 299 n_batches: 410 cost: 0.061386853 acc: 0.99\n",
            "epoch: 3 batch: 399 n_batches: 410 cost: 0.11160324 acc: 0.99\n",
            "Train acc: 0.9922926829268293 Test acc: 0.971\n",
            "epoch: 4 batch: 99 n_batches: 410 cost: 0.046049595 acc: 0.99\n",
            "epoch: 4 batch: 199 n_batches: 410 cost: 0.061395 acc: 0.98\n",
            "epoch: 4 batch: 299 n_batches: 410 cost: 0.031416163 acc: 0.99\n",
            "epoch: 4 batch: 399 n_batches: 410 cost: 0.101789884 acc: 0.96\n",
            "Train acc: 0.9955853658536585 Test acc: 0.969\n",
            "epoch: 5 batch: 99 n_batches: 410 cost: 0.037490826 acc: 0.98\n",
            "epoch: 5 batch: 199 n_batches: 410 cost: 0.047258466 acc: 0.98\n",
            "epoch: 5 batch: 299 n_batches: 410 cost: 0.0543952 acc: 0.99\n",
            "epoch: 5 batch: 399 n_batches: 410 cost: 0.035367355 acc: 0.99\n",
            "Train acc: 0.9973414634146341 Test acc: 0.97\n",
            "epoch: 6 batch: 99 n_batches: 410 cost: 0.018915229 acc: 0.99\n",
            "epoch: 6 batch: 199 n_batches: 410 cost: 0.013902665 acc: 1.00\n",
            "epoch: 6 batch: 299 n_batches: 410 cost: 0.01968325 acc: 0.99\n",
            "epoch: 6 batch: 399 n_batches: 410 cost: 0.02543137 acc: 1.00\n",
            "Train acc: 0.9979756097560976 Test acc: 0.972\n",
            "epoch: 7 batch: 99 n_batches: 410 cost: 0.007869129 acc: 1.00\n",
            "epoch: 7 batch: 199 n_batches: 410 cost: 0.038698833 acc: 0.99\n",
            "epoch: 7 batch: 299 n_batches: 410 cost: 0.025496889 acc: 0.99\n",
            "epoch: 7 batch: 399 n_batches: 410 cost: 0.01166245 acc: 1.00\n",
            "Train acc: 0.9991219512195122 Test acc: 0.974\n",
            "epoch: 8 batch: 99 n_batches: 410 cost: 0.0054320707 acc: 1.00\n",
            "epoch: 8 batch: 199 n_batches: 410 cost: 0.011812967 acc: 1.00\n",
            "epoch: 8 batch: 299 n_batches: 410 cost: 0.02033872 acc: 0.99\n",
            "epoch: 8 batch: 399 n_batches: 410 cost: 0.024453128 acc: 1.00\n",
            "Train acc: 0.9994146341463415 Test acc: 0.972\n",
            "epoch: 9 batch: 99 n_batches: 410 cost: 0.00653357 acc: 1.00\n",
            "epoch: 9 batch: 199 n_batches: 410 cost: 0.014193025 acc: 1.00\n",
            "epoch: 9 batch: 299 n_batches: 410 cost: 0.03607474 acc: 1.00\n",
            "epoch: 9 batch: 399 n_batches: 410 cost: 0.012776136 acc: 1.00\n",
            "Train acc: 0.9996585365853659 Test acc: 0.975\n",
            "epoch: 10 batch: 99 n_batches: 410 cost: 0.010195401 acc: 1.00\n",
            "epoch: 10 batch: 199 n_batches: 410 cost: 0.0048742546 acc: 1.00\n",
            "epoch: 10 batch: 299 n_batches: 410 cost: 0.01378185 acc: 1.00\n",
            "epoch: 10 batch: 399 n_batches: 410 cost: 0.0061391573 acc: 1.00\n",
            "Train acc: 0.9996829268292683 Test acc: 0.97\n",
            "epoch: 11 batch: 99 n_batches: 410 cost: 0.012656779 acc: 1.00\n",
            "epoch: 11 batch: 199 n_batches: 410 cost: 0.009676709 acc: 1.00\n",
            "epoch: 11 batch: 299 n_batches: 410 cost: 0.02013155 acc: 1.00\n",
            "epoch: 11 batch: 399 n_batches: 410 cost: 0.009115946 acc: 1.00\n",
            "Train acc: 0.9998048780487805 Test acc: 0.972\n",
            "epoch: 12 batch: 99 n_batches: 410 cost: 0.005715755 acc: 1.00\n",
            "epoch: 12 batch: 199 n_batches: 410 cost: 0.0036708938 acc: 1.00\n",
            "epoch: 12 batch: 299 n_batches: 410 cost: 0.002983586 acc: 1.00\n",
            "epoch: 12 batch: 399 n_batches: 410 cost: 0.0023256284 acc: 1.00\n",
            "Train acc: 0.9999024390243902 Test acc: 0.974\n",
            "epoch: 13 batch: 99 n_batches: 410 cost: 0.015666034 acc: 1.00\n",
            "epoch: 13 batch: 199 n_batches: 410 cost: 0.0027621912 acc: 1.00\n",
            "epoch: 13 batch: 299 n_batches: 410 cost: 0.014292546 acc: 1.00\n",
            "epoch: 13 batch: 399 n_batches: 410 cost: 0.037934743 acc: 0.98\n",
            "Train acc: 0.9998780487804878 Test acc: 0.973\n",
            "epoch: 14 batch: 99 n_batches: 410 cost: 0.0032598341 acc: 1.00\n",
            "epoch: 14 batch: 199 n_batches: 410 cost: 0.0026457927 acc: 1.00\n",
            "epoch: 14 batch: 299 n_batches: 410 cost: 0.00847359 acc: 1.00\n",
            "epoch: 14 batch: 399 n_batches: 410 cost: 0.0035333047 acc: 1.00\n",
            "Train acc: 0.9999024390243902 Test acc: 0.972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkQxAzBXBwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9999024390243902\n",
            "Test accuracy: 0.972\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}