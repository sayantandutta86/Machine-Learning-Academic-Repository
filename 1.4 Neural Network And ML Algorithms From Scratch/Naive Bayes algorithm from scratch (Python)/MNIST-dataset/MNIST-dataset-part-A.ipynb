{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "## MNIST Image Classification\n",
    "\n",
    "The MNIST dataset is a dataset of 60,000 training and 10,000 test examples of handwritten digits, originally constructed by Yann Lecun, Corinna Cortes, and Christopher J.C. Burges. It is very widely used to check simple methods. There are 10 classes in total (\"0\" to \"9\"). This dataset has been extensively studied, and there is a history of methods and feature constructions at https://en.wikipedia.org/wiki/MNIST_database and at the original site, http://yann.lecun.com/exdb/mnist/. You should notice that the best methods perform extremely well.\n",
    "\n",
    "The http://yann.lecun.com/exdb/mnist/ dataset is stored in an unusual format, described in detail on the page.  You do not have to write your own reader.  A web search should yield solutions for both Python and R.  For Python, https://pypi.org/project/python-mnist/ should work.  For R, there is reader code available at https://stackoverflow.com/questions/21521571/how-to-read-mnist-database-in-r. Please note that if you follow the recommendations in the accepted answer there at https://stackoverflow.com/a/21524980, you must also provide the readBin call with the flag signed=FALSE since the data values are stored as unsigned integers.\n",
    "\n",
    "The dataset consists of 28 x 28 images. These were originally binary images, but appear to be grey level images as a result of some anti-aliasing. I will ignore mid-grey pixels (there aren't many of them) and call dark pixels \"ink pixels\", and light pixels \"paper pixels\"; you can modify the data values with a threshold to specify the distinction, as described here https://en.wikipedia.org/wiki/Thresholding_(image_processing). The digit has been centered in the image by centering the center of gravity of the image pixels, but as mentioned on the original site, this is probably not ideal. Here are some options for re-centering the digits that I will refer to in the exercises.\n",
    "\n",
    "Untouched: Do not re-center the digits, but use the images as is.\n",
    "Bounding box: Construct a 20 x 20 bounding box so that the horizontal (resp. vertical) range of ink pixels is centered in the box.\n",
    "Stretched bounding box: Construct a 20 x 20 bounding box so that the horizontal (resp. vertical) range of ink pixels runs the full horizontal (resp. vertical) range of the box. Obtaining this representation will involve rescaling image pixels: you find the horizontal and vertical ink range, cut that out of the original image, then resize the result to 20 x 20. Once the image has been re-centered, you can compute features.\n",
    "\n",
    "### Question Part A: MNIST using naive Bayes\n",
    "\n",
    "Model each class of the dataset using a Normal distribution and (separately) a Bernoulli distribution for both untouched images v. stretched bounding boxes, using 20 x 20 for your bounding box dimension.  This should result in 4 total models.  Use the training set to calculate the distribution parameters.\n",
    "\n",
    "You must write the naive Bayes prediction code.  The distribution parameters can be calculated manually or via libraries.  Additionally, we recommend using a library to load the MNIST data (e.g. python-mnist or scikit-learn) and to rescale the images (e.g. openCV).\n",
    "\n",
    "Compute the accuracy values for the four combinations of Normal v. Bernoulli distributions for both untouched images v. stretched bounding boxes.  Both the training and test set accuracy will be reported.\n",
    "For each digit, plot the mean pixel values calculated for the Normal distribution of the untouched images.  In Python, a library such as matplotlib should prove useful.\n",
    "\n",
    "### Question Part B: MNIST using Decision Forest\n",
    "\n",
    "Classify MNIST using a decision forest.\n",
    "For your forest construction, you should investigate four cases. Your cases are: number of trees = (10, 30) X maximum depth = (4, 16). You should compute your accuracy for each of the following cases: untouched raw pixels; stretched bounding box. This yields a total of 8 slightly different classifiers. Please use 20 x 20 for your bounding box dimensions.\n",
    "\n",
    "You should use a decision forest library.  No need to write your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code: Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\sayan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\sayan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for untouched images using Normal distribution: 0.793\n",
      "Train accuracy for untouched images using Bernoulli distribution: 0.837\n",
      "Test accuracy for untouched images using Normal distribution: 0.7986\n",
      "Test accuracy for untouched images using Bernoulli distribution: 0.8434\n",
      "Train accuracy for cropped images using Normal distribution: 0.8105\n",
      "Train accuracy for cropped images using Bernoulli distribution: 0.817\n",
      "Test accuracy for cropped images using Normal distribution: 0.8105833333333333\n",
      "Test accuracy for cropped images using Bernoulli distribution: 0.8183333333333334\n"
     ]
    }
   ],
   "source": [
    "# Code: Homework #1 Problem #2A\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from scipy.stats import bernoulli as brn\n",
    "import random\n",
    "from scipy.misc import imresize\n",
    "\n",
    "def get_original_data(file):\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    data = df.as_matrix()\n",
    "    np.random.shuffle(data)\n",
    "    X = threshold_images(data[:,1:])\n",
    "    Y = data[:,0]\n",
    "    return X,Y\n",
    "\n",
    "def get_cropped_data(file):\n",
    "    df = pd.read_csv(file,header=None)\n",
    "    data = df.as_matrix()\n",
    "    np.random.shuffle(data)\n",
    "    X = threshold_images(crop_images(data[:,1:]))\n",
    "    Y = data[:,0]\n",
    "    return X,Y\n",
    "\n",
    "def crop_images(X_train):\n",
    "    a= int(X_train.shape[0])\n",
    "    X_train_crop = np.zeros(shape= (a,400))\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "      image = X_train[i].reshape(28,28)\n",
    "      row= np.unique(np.nonzero(image)[0])\n",
    "      col = np.unique(np.nonzero(image)[1])\n",
    "      image2 = image[min(row):max(row), min(col):max(col)]\n",
    "      value = imresize(image2, (20, 20))\n",
    "      X_train_crop[i] =  value.reshape(1,400)\n",
    "    return X_train_crop\n",
    "\n",
    "def threshold_images(X_train):\n",
    "    for i in range(len(X_train)):\n",
    "      for j in range(len(X_train[i])):\n",
    "        if X_train[i][j]<128:\n",
    "          X_train[i][j]=0\n",
    "        else:\n",
    "          X_train[i][j]=1\n",
    "    return X_train\n",
    "\n",
    "class NaiveBayes(object):\n",
    "    \n",
    "    def fit(self, X, Y, smoothing=10e-3):\n",
    "        self.gaussians = dict()\n",
    "        self.priors = dict()\n",
    "        labels = set(Y)\n",
    "        for c in labels:\n",
    "            current_x = X[Y == c]\n",
    "            self.gaussians[c] = {\n",
    "                'mean': current_x.mean(axis=0),\n",
    "                'var': current_x.var(axis=0) + smoothing,\n",
    "            }    \n",
    "            self.priors[c] = float(len(Y[Y==c])) / len(Y)\n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        P_norm, P_brn = self.predict(X)\n",
    "        return np.mean(P_norm==Y), np.mean(P_brn==Y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        N, D = X.shape\n",
    "        K = len(self.gaussians)\n",
    "        P_norm = np.zeros((N, K))\n",
    "        P_brn = np.zeros((N, K))\n",
    "        for c,g in self.gaussians.items():\n",
    "            mean, var = g['mean'], g['var']\n",
    "            P_norm[:,c] = mvn.logpdf(X, mean=mean, cov=var) + np.log(self.priors[c])\n",
    "            P_brn[:,c] = brn.logpmf(X, mean).sum(axis=1) + np.log(self.priors[c])\n",
    "                    \n",
    "        return np.argmax(P_norm, axis=1), np.argmax(P_brn, axis=1) \n",
    "    \n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    #Dataset for Test accuracy\n",
    "    X_train, y_train = get_original_data('mnist_train.csv')\n",
    "    X_test, y_test = get_original_data('mnist_test.csv')\n",
    "    \n",
    "    X_train_cropped, y_train_cropped = get_cropped_data('mnist_train.csv')\n",
    "    X_test_cropped, y_test_cropped = get_cropped_data('mnist_test.csv')\n",
    "    \n",
    "    #Dataset for training accuracy\n",
    "    Ntrain = int(len(y_train)*0.8)\n",
    "    \n",
    "    Xtrain, Ytrain = X_train[:Ntrain], y_train[:Ntrain]\n",
    "    Xtest, Ytest = X_train[Ntrain: ], y_train[Ntrain:]\n",
    "    \n",
    "    Xtrain_cropped, Ytrain_cropped = X_train_cropped[:Ntrain], y_train_cropped[:Ntrain]\n",
    "    Xtest_cropped, Ytest_cropped = X_train_cropped[Ntrain: ], y_train_cropped[Ntrain:]\n",
    "    \n",
    "    #Models\n",
    "    model = NaiveBayes()\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    model.norm_score, model.brn_score = model.score(Xtest,Ytest)\n",
    "    print(f'Train accuracy for untouched images using Normal distribution: {model.norm_score}')\n",
    "    print(f'Train accuracy for untouched images using Bernoulli distribution: {model.brn_score}')\n",
    "    \n",
    "    model_2 = NaiveBayes()\n",
    "    model_2.fit(X_train, y_train)\n",
    "    model_2.norm_score, model_2.brn_score = model_2.score(X_test,y_test)\n",
    "    print(f'Test accuracy for untouched images using Normal distribution: {model_2.norm_score}')\n",
    "    print(f'Test accuracy for untouched images using Bernoulli distribution: {model_2.brn_score}')\n",
    "    \n",
    "    model_3 = NaiveBayes()\n",
    "    model_3.fit(Xtrain_cropped, Ytrain_cropped)\n",
    "    model_3.norm_score, model_3.brn_score = model_3.score(Xtest_cropped,Ytest_cropped)\n",
    "    print(f'Train accuracy for cropped images using Normal distribution: {model_3.norm_score}')\n",
    "    print(f'Train accuracy for cropped images using Bernoulli distribution: {model_3.brn_score}')\n",
    "        \n",
    "    model_4 = NaiveBayes()\n",
    "    model_4.fit(X_train_cropped, y_train_cropped)\n",
    "    model_4.norm_score, model_4.brn_score = model_4.score(Xtest_cropped,Ytest_cropped)\n",
    "    print(f'Test accuracy for cropped images using Normal distribution: {model_4.norm_score}')\n",
    "    print(f'Test accuracy for cropped images using Bernoulli distribution: {model_4.brn_score}')\n",
    "    \n",
    "     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
