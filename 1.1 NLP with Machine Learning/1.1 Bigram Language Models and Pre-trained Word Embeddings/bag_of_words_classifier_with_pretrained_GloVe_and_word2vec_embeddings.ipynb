{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bag_of_words_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmmroQ1pXuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os; os.chdir('/content/drive/My Drive/Colab Notebooks/Lazy courses/NLP2/pretrained_data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLT8PE51pnk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from gensim.models import KeyedVectors "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnMFJIH073qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset\n",
        "# https://www.cs.umb.edu/~smimarog/textmining/datasets/\n",
        "\n",
        "train = pd.read_csv('r8-train-all-terms.txt', header = None, sep = '\\t')\n",
        "test = pd.read_csv('r8-test-all-terms.txt', header = None, sep = '\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_SBGsGBpntm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.columns = ['label', 'content']\n",
        "test.columns = ['label', 'content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL4OfpxopnnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "08d1884f-46f2-48cd-f413-a99f3ac6dd2e"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>earn</td>\n",
              "      <td>champion products ch approves stock split cham...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acq</td>\n",
              "      <td>computer terminal systems cpml completes sale ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>earn</td>\n",
              "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>earn</td>\n",
              "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>earn</td>\n",
              "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            content\n",
              "0  earn  champion products ch approves stock split cham...\n",
              "1   acq  computer terminal systems cpml completes sale ...\n",
              "2  earn  cobanco inc cbco year net shr cts vs dlrs net ...\n",
              "3  earn  am international inc am nd qtr jan oper shr lo...\n",
              "4  earn  brown forman inc bfd th qtr net shr one dlr vs..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDB4gJP8pnpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9c42c833-1304-4f87-cebd-fcdbb2916491"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trade</td>\n",
              "      <td>asian exporters fear damage from u s japan rif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>grain</td>\n",
              "      <td>china daily says vermin eat pct grain stocks a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ship</td>\n",
              "      <td>australian foreign ship ban ends but nsw ports...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>acq</td>\n",
              "      <td>sumitomo bank aims at quick recovery from merg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>earn</td>\n",
              "      <td>amatil proposes two for five bonus share issue...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            content\n",
              "0  trade  asian exporters fear damage from u s japan rif...\n",
              "1  grain  china daily says vermin eat pct grain stocks a...\n",
              "2   ship  australian foreign ship ban ends but nsw ports...\n",
              "3    acq  sumitomo bank aims at quick recovery from merg...\n",
              "4   earn  amatil proposes two for five bonus share issue..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4uz4cJnpnz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GloveVectorizer():\n",
        "    def __init__(self):\n",
        "        #load in pretrained word vectors\n",
        "        print(\"Loading GloVe pre-trained word vectors\")\n",
        "        word2vec = {}\n",
        "        embedding = []\n",
        "        idx2word = []\n",
        "        with open('glove.6B.50d.txt') as f:\n",
        "            #this is a space separated text file in the format\n",
        "            #word vec[0] vec[1] vec[2] ...\n",
        "            for line in f:\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                vec = np.asarray(values[1:], dtype='float32')\n",
        "                word2vec[word] = vec\n",
        "                embedding.append(vec)\n",
        "                idx2word.append(word)\n",
        "            print(f'Found {len(word2vec)} word vectors')\n",
        "\n",
        "        #Save for later\n",
        "        self.word2vec = word2vec\n",
        "        self.embedding = np.array(embedding)\n",
        "        self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
        "        self.V, self.D = self.embedding.shape\n",
        "\n",
        "    def fit(self, data):\n",
        "        pass\n",
        "\n",
        "    def transform(self, data):\n",
        "        X = np.zeros((len(data), self.D))\n",
        "        n=0\n",
        "        emptycount = 0\n",
        "        for sentence in data:\n",
        "            tokens = sentence.lower().split()\n",
        "            vecs = []\n",
        "            for word in tokens:\n",
        "                if word in self.word2vec:\n",
        "                    vec = self.word2vec[word]\n",
        "                    vecs.append(vec)\n",
        "            if len(vecs) > 0:\n",
        "                vecs = np.array(vecs)\n",
        "                X[n] = vecs.mean(axis=0)\n",
        "            else:\n",
        "                emptycount += 1\n",
        "            n += 1\n",
        "        print(f\"Number of samples with no words found: {emptycount} / {len(data)}\")\n",
        "        return X\n",
        "\n",
        "    def fit_transform(self, data):\n",
        "        self.fit(data)\n",
        "        return self.transform(data)\n",
        "\n",
        "\n",
        "class Word2VecVectorizer:\n",
        "    def __init__(self):\n",
        "        print(\"Loading in word vectors..\")\n",
        "        self.word_vectors = KeyedVectors.load_word2vec_format(\n",
        "            'GoogleNews-vectors-negative300.bin', binary=True\n",
        "        )\n",
        "        print(\"Word vectors loaded...\")\n",
        "\n",
        "    def fit(self, data):\n",
        "        pass\n",
        "\n",
        "    def transform(self, data):\n",
        "        #determine the dimensionality of the vectors\n",
        "        v = self.word_vectors.get_vector('king')\n",
        "        self.D = v.shape[0]\n",
        "\n",
        "        X = np.zeros((len(data), self.D))\n",
        "        n = 0\n",
        "        emptycount = 0\n",
        "        for sentence in data:\n",
        "            tokens = sentence.split()\n",
        "            vecs = []\n",
        "            m = 0\n",
        "            for word in tokens:\n",
        "                try:\n",
        "                    #throw key error if word is not found\n",
        "                    vec = self.word_vectors.get_vector(word)\n",
        "                    vecs.append(vec)\n",
        "                    m += 1\n",
        "                except KeyError:\n",
        "                    pass\n",
        "            if len(vecs) > 0:\n",
        "                vecs = np.array(vecs)\n",
        "                X[n] = vecs.mean(axis=0)\n",
        "            else:\n",
        "                emptycount += 1\n",
        "            n += 1\n",
        "\n",
        "            print(f\"Number of samples with no words: {emptycount} / {len(data)} \")\n",
        "            return X\n",
        "\n",
        "    def fit_transform(self, data):\n",
        "        self.fit(data)\n",
        "        return self.transform(data) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqfgVIUbpn2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ed1bc77e-3d06-4e56-9cb1-23548cac4ae5"
      },
      "source": [
        "#GloVe\n",
        "vectorizer = GloveVectorizer()\n",
        "Xtrain1 = vectorizer.fit_transform(train.content)\n",
        "Ytrain1 = train.label\n",
        "\n",
        "Xtest1 = vectorizer.transform(test.content)\n",
        "Ytest1 = test.label"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading GloVe pre-trained word vectors\n",
            "Found 400000 word vectors\n",
            "Number of samples with no words found: 0 / 5485\n",
            "Number of samples with no words found: 0 / 2189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PofFn5_xpn6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68f89d03-b978-480f-94ce-f690970f9697"
      },
      "source": [
        "#create the model, train it, print scores\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(Xtrain1, Ytrain1)\n",
        "print(\"train score:\", model.score(Xtrain1, Ytrain1))\n",
        "print(\"test score:\", model.score(Xtest1, Ytest1))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train score: 0.9992707383773929\n",
            "test score: 0.9323892188213796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNuECqLLpn8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8bc2bfcf-0148-47a8-b78f-92bd0cd2b1f2"
      },
      "source": [
        "#Word2vec\n",
        "\n",
        "train = pd.read_csv('r8-train-all-terms.txt', header = None, sep = '\\t')\n",
        "test = pd.read_csv('r8-test-all-terms.txt', header = None, sep = '\\t')\n",
        "train.columns = ['label', 'content']\n",
        "test.columns = ['label', 'content']\n",
        "\n",
        "\n",
        "vectorizer = Word2VecVectorizer()\n",
        "Xtrain2 = vectorizer.fit_transform(train.content)\n",
        "Ytrain2 = train.label\n",
        "\n",
        "Xtest2 = vectorizer.transform(test.content)\n",
        "Ytest2 = test.label\n",
        "\n",
        "#create the model, train it, print scores\n",
        "model = RandomForestClassifier(n_estimators=2000)\n",
        "model.fit(Xtrain2, Ytrain2)\n",
        "print(\"train score:\", model.score(Xtrain2, Ytrain2))\n",
        "print(\"test score:\", model.score(Xtest2, Ytest2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading in word vectors..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Word vectors loaded...\n",
            "Number of samples with no words: 0 / 5485 \n",
            "Number of samples with no words: 0 / 2189 \n",
            "train score: 0.5177757520510483\n",
            "test score: 0.49474645957058017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3VPNN6ypn4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQUO8t5tpnyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVncj_GLpnw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJv3GECWpnr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}