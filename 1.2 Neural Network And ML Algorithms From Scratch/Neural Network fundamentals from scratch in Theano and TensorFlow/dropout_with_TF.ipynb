{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dropout_with_TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yR0ohHpPDbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Lazy courses/DS:Deep Learning in Python/NN -Fundamental concepts from scratch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkppimesPG4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dac56e4-1e54-4e79-9592-c53023b0c7ab"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from util import get_normalized_data\n",
        "#from sklearn.utils import shuffle\n",
        "\n",
        "class HiddenLayer(object):\n",
        "    def __init__(self, M1, M2):\n",
        "        self.M1 = M1\n",
        "        self.M2 = M2\n",
        "        W = np.random.randn(M1, M2) * np.sqrt(2.0 / M1)\n",
        "        b = np.zeros(M2)\n",
        "        self.W = tf.Variable(W.astype(np.float32))\n",
        "        self.b = tf.Variable(b.astype(np.float32))\n",
        "        self.params = [self.W, self.b]\n",
        "\n",
        "    def forward(self, X):\n",
        "        return tf.nn.relu(tf.matmul(X, self.W) + self.b)\n",
        "\n",
        "\n",
        "class ANN(object):\n",
        "    def __init__(self, hidden_layer_sizes, p_keep):\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "        self.dropout_rates = p_keep\n",
        "\n",
        "    def fit(self, X, Y, Xvalid, Yvalid, lr=1e-4, mu=0.9, decay=0.9, epochs=15, batch_sz=100, print_every=50):\n",
        "        X = X.astype(np.float32)\n",
        "        Y = Y.astype(np.int64)\n",
        "        Xvalid = Xvalid.astype(np.float32)\n",
        "        Yvalid = Yvalid.astype(np.int64)\n",
        "\n",
        "        # initialize hidden layers\n",
        "        N, D = X.shape\n",
        "        K = len(set(Y))\n",
        "        self.hidden_layers = []\n",
        "        M1 = D\n",
        "        for M2 in self.hidden_layer_sizes:\n",
        "            h = HiddenLayer(M1, M2)\n",
        "            self.hidden_layers.append(h)\n",
        "            M1 = M2\n",
        "        W = np.random.randn(M1, K) * np.sqrt(2.0 / M1)\n",
        "        b = np.zeros(K)\n",
        "        self.W = tf.Variable(W.astype(np.float32))\n",
        "        self.b = tf.Variable(b.astype(np.float32))\n",
        "\n",
        "        # collect params for later use\n",
        "        self.params = [self.W, self.b]\n",
        "        for h in self.hidden_layers:\n",
        "            self.params += h.params\n",
        "\n",
        "        # set up theano functions and variables\n",
        "        inputs = tf.placeholder(tf.float32, shape=(None, D), name='inputs')\n",
        "        labels = tf.placeholder(tf.int64, shape=(None,), name='labels')\n",
        "        logits = self.forward(inputs)\n",
        "\n",
        "        cost = tf.reduce_mean(\n",
        "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                logits=logits,\n",
        "                labels=labels\n",
        "            )\n",
        "        )\n",
        "        train_op = tf.train.RMSPropOptimizer(lr, decay=decay, momentum=mu).minimize(cost)\n",
        "        # train_op = tf.train.MomentumOptimizer(lr, momentum=mu).minimize(cost)\n",
        "        # train_op = tf.train.AdamOptimizer(lr).minimize(cost)\n",
        "        prediction = self.predict(inputs)\n",
        "\n",
        "        # validation cost will be calculated separately since nothing will be dropped\n",
        "        test_logits = self.forward_test(inputs)\n",
        "        test_cost = tf.reduce_mean(\n",
        "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                logits=test_logits,\n",
        "                labels=labels\n",
        "            )\n",
        "        )\n",
        "\n",
        "        n_batches = N // batch_sz\n",
        "        costs = []\n",
        "        init = tf.global_variables_initializer()\n",
        "        with tf.Session() as session:\n",
        "            session.run(init)\n",
        "            for i in range(epochs):\n",
        "                print(\"epoch:\", i, \"n_batches:\", n_batches)\n",
        "                X, Y = shuffle(X, Y)\n",
        "                for j in range(n_batches):\n",
        "                    Xbatch = X[j*batch_sz:(j*batch_sz+batch_sz)]\n",
        "                    Ybatch = Y[j*batch_sz:(j*batch_sz+batch_sz)]\n",
        "\n",
        "                    session.run(train_op, feed_dict={inputs: Xbatch, labels: Ybatch})\n",
        "\n",
        "                    if j % print_every == 0:\n",
        "                        c = session.run(test_cost, feed_dict={inputs: Xvalid, labels: Yvalid})\n",
        "                        p = session.run(prediction, feed_dict={inputs: Xvalid})\n",
        "                        costs.append(c)\n",
        "                        e = error_rate(Yvalid, p)\n",
        "                        print(\"i:\", i, \"j:\", j, \"nb:\", n_batches, \"cost:\", c, \"error rate:\", e)\n",
        "        \n",
        "        plt.plot(costs)\n",
        "        plt.show()\n",
        "\n",
        "    def forward(self, X):\n",
        "        # tf.nn.dropout scales inputs by 1/p_keep\n",
        "        # therefore, during test time, we don't have to scale anything\n",
        "        Z = X\n",
        "        Z = tf.nn.dropout(Z, self.dropout_rates[0])\n",
        "        for h, p in zip(self.hidden_layers, self.dropout_rates[1:]):\n",
        "            Z = h.forward(Z)\n",
        "            Z = tf.nn.dropout(Z, p)\n",
        "        return tf.matmul(Z, self.W) + self.b\n",
        "\n",
        "    def forward_test(self, X):\n",
        "        Z = X\n",
        "        for h in self.hidden_layers:\n",
        "            Z = h.forward(Z)\n",
        "        return tf.matmul(Z, self.W) + self.b\n",
        "\n",
        "    def predict(self, X):\n",
        "        pY = self.forward_test(X)\n",
        "        return tf.argmax(pY, 1)\n",
        "\n",
        "\n",
        "def error_rate(p, t):\n",
        "    return np.mean(p != t)\n",
        "\n",
        "\n",
        "def relu(a):\n",
        "    return a * (a > 0)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # step 1: get the data and define all the usual variables\n",
        "    Xtrain, Xtest, Ytrain, Ytest = get_normalized_data()\n",
        "\n",
        "    ann = ANN([500, 300], [0.8, 0.5, 0.5])\n",
        "    ann.fit(Xtrain, Ytrain, Xtest, Ytest)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading in and transforming data\n",
            "epoch: 0 n_batches: 410\n",
            "i: 0 j: 0 nb: 410 cost: 3.4789686 error rate: 0.92\n",
            "i: 0 j: 50 nb: 410 cost: 2.060212 error rate: 0.619\n",
            "i: 0 j: 100 nb: 410 cost: 0.7856274 error rate: 0.169\n",
            "i: 0 j: 150 nb: 410 cost: 0.5130367 error rate: 0.104\n",
            "i: 0 j: 200 nb: 410 cost: 0.3696076 error rate: 0.091\n",
            "i: 0 j: 250 nb: 410 cost: 0.35043624 error rate: 0.081\n",
            "i: 0 j: 300 nb: 410 cost: 0.26105028 error rate: 0.078\n",
            "i: 0 j: 350 nb: 410 cost: 0.26058137 error rate: 0.069\n",
            "i: 0 j: 400 nb: 410 cost: 0.26415175 error rate: 0.064\n",
            "epoch: 1 n_batches: 410\n",
            "i: 1 j: 0 nb: 410 cost: 0.27080604 error rate: 0.063\n",
            "i: 1 j: 50 nb: 410 cost: 0.24804135 error rate: 0.064\n",
            "i: 1 j: 100 nb: 410 cost: 0.2683737 error rate: 0.063\n",
            "i: 1 j: 150 nb: 410 cost: 0.19571424 error rate: 0.062\n",
            "i: 1 j: 200 nb: 410 cost: 0.18091302 error rate: 0.058\n",
            "i: 1 j: 250 nb: 410 cost: 0.21584198 error rate: 0.056\n",
            "i: 1 j: 300 nb: 410 cost: 0.24306288 error rate: 0.052\n",
            "i: 1 j: 350 nb: 410 cost: 0.21338317 error rate: 0.049\n",
            "i: 1 j: 400 nb: 410 cost: 0.20061657 error rate: 0.047\n",
            "epoch: 2 n_batches: 410\n",
            "i: 2 j: 0 nb: 410 cost: 0.18924807 error rate: 0.045\n",
            "i: 2 j: 50 nb: 410 cost: 0.19149733 error rate: 0.044\n",
            "i: 2 j: 100 nb: 410 cost: 0.17554536 error rate: 0.047\n",
            "i: 2 j: 150 nb: 410 cost: 0.19513556 error rate: 0.046\n",
            "i: 2 j: 200 nb: 410 cost: 0.20796147 error rate: 0.043\n",
            "i: 2 j: 250 nb: 410 cost: 0.13998698 error rate: 0.04\n",
            "i: 2 j: 300 nb: 410 cost: 0.14381488 error rate: 0.043\n",
            "i: 2 j: 350 nb: 410 cost: 0.18397601 error rate: 0.041\n",
            "i: 2 j: 400 nb: 410 cost: 0.18228866 error rate: 0.043\n",
            "epoch: 3 n_batches: 410\n",
            "i: 3 j: 0 nb: 410 cost: 0.20531376 error rate: 0.042\n",
            "i: 3 j: 50 nb: 410 cost: 0.17371836 error rate: 0.041\n",
            "i: 3 j: 100 nb: 410 cost: 0.15921901 error rate: 0.038\n",
            "i: 3 j: 150 nb: 410 cost: 0.18373367 error rate: 0.04\n",
            "i: 3 j: 200 nb: 410 cost: 0.19474067 error rate: 0.047\n",
            "i: 3 j: 250 nb: 410 cost: 0.15581511 error rate: 0.047\n",
            "i: 3 j: 300 nb: 410 cost: 0.14318733 error rate: 0.038\n",
            "i: 3 j: 350 nb: 410 cost: 0.14140883 error rate: 0.041\n",
            "i: 3 j: 400 nb: 410 cost: 0.14436582 error rate: 0.039\n",
            "epoch: 4 n_batches: 410\n",
            "i: 4 j: 0 nb: 410 cost: 0.14732224 error rate: 0.035\n",
            "i: 4 j: 50 nb: 410 cost: 0.1395567 error rate: 0.04\n",
            "i: 4 j: 100 nb: 410 cost: 0.1735209 error rate: 0.04\n",
            "i: 4 j: 150 nb: 410 cost: 0.18118037 error rate: 0.042\n",
            "i: 4 j: 200 nb: 410 cost: 0.1813123 error rate: 0.038\n",
            "i: 4 j: 250 nb: 410 cost: 0.13606617 error rate: 0.035\n",
            "i: 4 j: 300 nb: 410 cost: 0.135198 error rate: 0.033\n",
            "i: 4 j: 350 nb: 410 cost: 0.12623307 error rate: 0.035\n",
            "i: 4 j: 400 nb: 410 cost: 0.12970811 error rate: 0.036\n",
            "epoch: 5 n_batches: 410\n",
            "i: 5 j: 0 nb: 410 cost: 0.1289324 error rate: 0.035\n",
            "i: 5 j: 50 nb: 410 cost: 0.13595022 error rate: 0.033\n",
            "i: 5 j: 100 nb: 410 cost: 0.17129403 error rate: 0.035\n",
            "i: 5 j: 150 nb: 410 cost: 0.17562413 error rate: 0.034\n",
            "i: 5 j: 200 nb: 410 cost: 0.1816207 error rate: 0.032\n",
            "i: 5 j: 250 nb: 410 cost: 0.18376741 error rate: 0.035\n",
            "i: 5 j: 300 nb: 410 cost: 0.13790844 error rate: 0.04\n",
            "i: 5 j: 350 nb: 410 cost: 0.12824886 error rate: 0.035\n",
            "i: 5 j: 400 nb: 410 cost: 0.14249581 error rate: 0.034\n",
            "epoch: 6 n_batches: 410\n",
            "i: 6 j: 0 nb: 410 cost: 0.14901425 error rate: 0.033\n",
            "i: 6 j: 50 nb: 410 cost: 0.13405502 error rate: 0.03\n",
            "i: 6 j: 100 nb: 410 cost: 0.160881 error rate: 0.03\n",
            "i: 6 j: 150 nb: 410 cost: 0.13014977 error rate: 0.033\n",
            "i: 6 j: 200 nb: 410 cost: 0.23045605 error rate: 0.028\n",
            "i: 6 j: 250 nb: 410 cost: 0.2177904 error rate: 0.03\n",
            "i: 6 j: 300 nb: 410 cost: 0.1813125 error rate: 0.033\n",
            "i: 6 j: 350 nb: 410 cost: 0.12489735 error rate: 0.032\n",
            "i: 6 j: 400 nb: 410 cost: 0.16215163 error rate: 0.033\n",
            "epoch: 7 n_batches: 410\n",
            "i: 7 j: 0 nb: 410 cost: 0.1773424 error rate: 0.032\n",
            "i: 7 j: 50 nb: 410 cost: 0.1651579 error rate: 0.03\n",
            "i: 7 j: 100 nb: 410 cost: 0.17895769 error rate: 0.03\n",
            "i: 7 j: 150 nb: 410 cost: 0.15291594 error rate: 0.034\n",
            "i: 7 j: 200 nb: 410 cost: 0.12284494 error rate: 0.028\n",
            "i: 7 j: 250 nb: 410 cost: 0.12640549 error rate: 0.028\n",
            "i: 7 j: 300 nb: 410 cost: 0.1214476 error rate: 0.033\n",
            "i: 7 j: 350 nb: 410 cost: 0.13470584 error rate: 0.036\n",
            "i: 7 j: 400 nb: 410 cost: 0.14357358 error rate: 0.034\n",
            "epoch: 8 n_batches: 410\n",
            "i: 8 j: 0 nb: 410 cost: 0.15355632 error rate: 0.037\n",
            "i: 8 j: 50 nb: 410 cost: 0.18075433 error rate: 0.033\n",
            "i: 8 j: 100 nb: 410 cost: 0.19726461 error rate: 0.036\n",
            "i: 8 j: 150 nb: 410 cost: 0.14949387 error rate: 0.03\n",
            "i: 8 j: 200 nb: 410 cost: 0.2240708 error rate: 0.033\n",
            "i: 8 j: 250 nb: 410 cost: 0.14092673 error rate: 0.033\n",
            "i: 8 j: 300 nb: 410 cost: 0.13502012 error rate: 0.033\n",
            "i: 8 j: 350 nb: 410 cost: 0.12693058 error rate: 0.033\n",
            "i: 8 j: 400 nb: 410 cost: 0.124532305 error rate: 0.031\n",
            "epoch: 9 n_batches: 410\n",
            "i: 9 j: 0 nb: 410 cost: 0.1369795 error rate: 0.03\n",
            "i: 9 j: 50 nb: 410 cost: 0.16313905 error rate: 0.033\n",
            "i: 9 j: 100 nb: 410 cost: 0.1194522 error rate: 0.028\n",
            "i: 9 j: 150 nb: 410 cost: 0.13329697 error rate: 0.032\n",
            "i: 9 j: 200 nb: 410 cost: 0.13854167 error rate: 0.033\n",
            "i: 9 j: 250 nb: 410 cost: 0.13464582 error rate: 0.031\n",
            "i: 9 j: 300 nb: 410 cost: 0.14199103 error rate: 0.033\n",
            "i: 9 j: 350 nb: 410 cost: 0.12983479 error rate: 0.029\n",
            "i: 9 j: 400 nb: 410 cost: 0.24909484 error rate: 0.03\n",
            "epoch: 10 n_batches: 410\n",
            "i: 10 j: 0 nb: 410 cost: 0.21992007 error rate: 0.031\n",
            "i: 10 j: 50 nb: 410 cost: 0.10931825 error rate: 0.034\n",
            "i: 10 j: 100 nb: 410 cost: 0.15552524 error rate: 0.035\n",
            "i: 10 j: 150 nb: 410 cost: 0.15345408 error rate: 0.031\n",
            "i: 10 j: 200 nb: 410 cost: 0.23585303 error rate: 0.031\n",
            "i: 10 j: 250 nb: 410 cost: 0.13448209 error rate: 0.038\n",
            "i: 10 j: 300 nb: 410 cost: 0.15230446 error rate: 0.034\n",
            "i: 10 j: 350 nb: 410 cost: 0.1319361 error rate: 0.033\n",
            "i: 10 j: 400 nb: 410 cost: 0.116330735 error rate: 0.033\n",
            "epoch: 11 n_batches: 410\n",
            "i: 11 j: 0 nb: 410 cost: 0.11940611 error rate: 0.032\n",
            "i: 11 j: 50 nb: 410 cost: 0.16167325 error rate: 0.03\n",
            "i: 11 j: 100 nb: 410 cost: 0.1311389 error rate: 0.029\n",
            "i: 11 j: 150 nb: 410 cost: 0.15376931 error rate: 0.03\n",
            "i: 11 j: 200 nb: 410 cost: 0.14303198 error rate: 0.035\n",
            "i: 11 j: 250 nb: 410 cost: 0.1172373 error rate: 0.03\n",
            "i: 11 j: 300 nb: 410 cost: 0.119449176 error rate: 0.027\n",
            "i: 11 j: 350 nb: 410 cost: 0.1290053 error rate: 0.028\n",
            "i: 11 j: 400 nb: 410 cost: 0.1250404 error rate: 0.028\n",
            "epoch: 12 n_batches: 410\n",
            "i: 12 j: 0 nb: 410 cost: 0.12217255 error rate: 0.027\n",
            "i: 12 j: 50 nb: 410 cost: 0.12785879 error rate: 0.029\n",
            "i: 12 j: 100 nb: 410 cost: 0.28061154 error rate: 0.028\n",
            "i: 12 j: 150 nb: 410 cost: 0.12333045 error rate: 0.03\n",
            "i: 12 j: 200 nb: 410 cost: 0.11739305 error rate: 0.026\n",
            "i: 12 j: 250 nb: 410 cost: 0.120813474 error rate: 0.028\n",
            "i: 12 j: 300 nb: 410 cost: 0.1231534 error rate: 0.03\n",
            "i: 12 j: 350 nb: 410 cost: 0.11025855 error rate: 0.025\n",
            "i: 12 j: 400 nb: 410 cost: 0.107415475 error rate: 0.031\n",
            "epoch: 13 n_batches: 410\n",
            "i: 13 j: 0 nb: 410 cost: 0.11109175 error rate: 0.032\n",
            "i: 13 j: 50 nb: 410 cost: 0.120658435 error rate: 0.035\n",
            "i: 13 j: 100 nb: 410 cost: 0.122813806 error rate: 0.029\n",
            "i: 13 j: 150 nb: 410 cost: 0.12474889 error rate: 0.035\n",
            "i: 13 j: 200 nb: 410 cost: 0.12942937 error rate: 0.031\n",
            "i: 13 j: 250 nb: 410 cost: 0.10715806 error rate: 0.028\n",
            "i: 13 j: 300 nb: 410 cost: 0.10455875 error rate: 0.027\n",
            "i: 13 j: 350 nb: 410 cost: 0.13834298 error rate: 0.031\n",
            "i: 13 j: 400 nb: 410 cost: 0.1147086 error rate: 0.031\n",
            "epoch: 14 n_batches: 410\n",
            "i: 14 j: 0 nb: 410 cost: 0.11628788 error rate: 0.032\n",
            "i: 14 j: 50 nb: 410 cost: 0.12011599 error rate: 0.03\n",
            "i: 14 j: 100 nb: 410 cost: 0.16897164 error rate: 0.029\n",
            "i: 14 j: 150 nb: 410 cost: 0.108036205 error rate: 0.026\n",
            "i: 14 j: 200 nb: 410 cost: 0.10726323 error rate: 0.027\n",
            "i: 14 j: 250 nb: 410 cost: 0.11304627 error rate: 0.028\n",
            "i: 14 j: 300 nb: 410 cost: 0.1071212 error rate: 0.029\n",
            "i: 14 j: 350 nb: 410 cost: 0.11796157 error rate: 0.032\n",
            "i: 14 j: 400 nb: 410 cost: 0.11563785 error rate: 0.028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}