{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtxrfsOj_uPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Lazy courses/CNN course/data')\n",
        "\n",
        "#Data downloaded from: http://ufldl.stanford.edu/housenumbers/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0T98UOvrit7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "f448b35d-3219-4ac4-f61b-9a75bcbd4e72"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from sklearn.utils import shuffle\n",
        "from datetime import datetime\n",
        "\n",
        "def y2indicator(y):\n",
        "    N = len(y)\n",
        "    ind = np.zeros((N, 10))\n",
        "    for i in range(N):\n",
        "        ind[i, y[i]] = 1\n",
        "    return ind\n",
        "\n",
        "def error_rate(p, t):\n",
        "    return np.mean(p != t)\n",
        "\n",
        "def flatten(X):\n",
        "    #input dim - (32, 32, 3, N)\n",
        "    #Output will be (N, 3072)\n",
        "    N = X.shape[-1]\n",
        "    flat = np.zeros(((N, 3072)))\n",
        "    for i in range(N):\n",
        "        flat[i] = X[:,:,:,i].reshape(3072)\n",
        "    return flat\n",
        "\n",
        "def get_data():\n",
        "    train = loadmat('/content/drive/My Drive/Colab Notebooks/Lazy courses/CNN course/data/train_32x32.mat')\n",
        "    test = loadmat('/content/drive/My Drive/Colab Notebooks/Lazy courses/CNN course/data/test_32x32.mat')\n",
        "    return train, test"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NETWMAuHFNd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00c2cf1d-c633-4f47-ab27-ee3a53cd4462"
      },
      "source": [
        "def main():\n",
        "    train, test = get_data()\n",
        "\n",
        "    #scaling the images (X), and, Y is Nx1 matrix from 1-10 in matlab, need to change to 0-9\n",
        "    Xtrain = flatten(train['X'].astype(np.float32) / 255)\n",
        "    Ytrain = train['y'].flatten() - 1\n",
        "    Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
        "    Ytrain_ind = y2indicator(Ytrain)\n",
        "\n",
        "    Xtest = flatten(test['X'].astype(np.float32) / 255)\n",
        "    Ytest = test['y'].flatten() - 1\n",
        "    Ytest_ind = y2indicator(Ytest)\n",
        "\n",
        "    #gradient descent params\n",
        "    max_iter = 20\n",
        "    print_period = 10\n",
        "    N, D = Xtrain.shape\n",
        "    batch_sz = 500\n",
        "    n_batches = N / batch_sz\n",
        "\n",
        "    #initial weights\n",
        "    M1 = 1000 #hidden layer size\n",
        "    M2 = 500\n",
        "    K = 10\n",
        "    W1_init = np.random.randn(D, M1) / np.sqrt(D + M1)\n",
        "    b1_init = np.zeros(M1)\n",
        "    W2_init = np.random.randn(M1, M2)\n",
        "    b2_init = np.zeros(M2)\n",
        "    W3_init = np.random.randn(M2, 10) / np.sqrt(K + M2)\n",
        "    b3_init = np.zeros(K)\n",
        "\n",
        "    #define variables and expressions\n",
        "    X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
        "    T = tf.placeholder(tf.float32, shape=(None, K), name='T')\n",
        "    W1 = tf.Variable(W1_init.astype(np.float32))\n",
        "    b1 = tf.Variable(b1_init.astype(np.float32))\n",
        "    W2 = tf.Variable(W2_init.astype(np.float32))\n",
        "    b2 = tf.Variable(b2_init.astype(np.float32))\n",
        "    W3 = tf.Variable(W3_init.astype(np.float32))\n",
        "    b3 = tf.Variable(b3_init.astype(np.float32))\n",
        "\n",
        "    Z1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
        "    Z2 = tf.nn.relu(tf.matmul(Z1, W2) + b2)\n",
        "    Yish = tf.matmul(Z2, W3) + b3\n",
        "\n",
        "    cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=Yish, labels=T))\n",
        "\n",
        "    train_op = tf.train.RMSPropOptimizer(0.0001, decay=0.99, momentum=0.9).minimize(cost)\n",
        "\n",
        "    predict_op = tf.argmax(Yish, 1)\n",
        "\n",
        "    t0 = datetime.now()\n",
        "    LL = []\n",
        "    init = tf.global_variables_initializer()\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "\n",
        "        for i in range(max_iter):\n",
        "            for j in range(int(n_batches)):\n",
        "                Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
        "                Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
        "\n",
        "                session.run(train_op, feed_dict={X: Xbatch, T:Ybatch})\n",
        "                if j % print_period == 0:\n",
        "                    test_cost = session.run(cost, feed_dict={X: Xtest, T: Ytest_ind})\n",
        "                    prediction = session.run(predict_op, feed_dict={X: Xtest})\n",
        "                    err = error_rate(prediction, Ytest)\n",
        "                    print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" %(i, j, test_cost, err))\n",
        "                    LL.append(test_cost)\n",
        "    print(\"Elapsed time: \", (datetime.now() - t0))\n",
        "    plt.plot(LL)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-8eac3bf521de>:46: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Cost / err at iteration i=0, j=0: 1536528.250 / 0.924\n",
            "Cost / err at iteration i=0, j=10: 10892044.000 / 0.939\n",
            "Cost / err at iteration i=0, j=20: 2223084.250 / 0.804\n",
            "Cost / err at iteration i=0, j=30: 3771118.500 / 0.908\n",
            "Cost / err at iteration i=0, j=40: 1590523.125 / 0.922\n",
            "Cost / err at iteration i=0, j=50: 1791644.625 / 0.889\n",
            "Cost / err at iteration i=0, j=60: 1186720.000 / 0.841\n",
            "Cost / err at iteration i=0, j=70: 960827.375 / 0.935\n",
            "Cost / err at iteration i=0, j=80: 948770.375 / 0.889\n",
            "Cost / err at iteration i=0, j=90: 671842.625 / 0.922\n",
            "Cost / err at iteration i=0, j=100: 496259.188 / 0.849\n",
            "Cost / err at iteration i=0, j=110: 452472.844 / 0.923\n",
            "Cost / err at iteration i=0, j=120: 471613.188 / 0.936\n",
            "Cost / err at iteration i=0, j=130: 364179.719 / 0.925\n",
            "Cost / err at iteration i=0, j=140: 688393.625 / 0.903\n",
            "Cost / err at iteration i=1, j=0: 272224.188 / 0.889\n",
            "Cost / err at iteration i=1, j=10: 518710.125 / 0.804\n",
            "Cost / err at iteration i=1, j=20: 731998.812 / 0.908\n",
            "Cost / err at iteration i=1, j=30: 259334.578 / 0.895\n",
            "Cost / err at iteration i=1, j=40: 459199.875 / 0.916\n",
            "Cost / err at iteration i=1, j=50: 431605.688 / 0.939\n",
            "Cost / err at iteration i=1, j=60: 254231.578 / 0.912\n",
            "Cost / err at iteration i=1, j=70: 427777.500 / 0.939\n",
            "Cost / err at iteration i=1, j=80: 265563.438 / 0.804\n",
            "Cost / err at iteration i=1, j=90: 313738.938 / 0.917\n",
            "Cost / err at iteration i=1, j=100: 337694.062 / 0.860\n",
            "Cost / err at iteration i=1, j=110: 250465.625 / 0.801\n",
            "Cost / err at iteration i=1, j=120: 281008.750 / 0.894\n",
            "Cost / err at iteration i=1, j=130: 252380.172 / 0.803\n",
            "Cost / err at iteration i=1, j=140: 215864.500 / 0.929\n",
            "Cost / err at iteration i=2, j=0: 167274.906 / 0.897\n",
            "Cost / err at iteration i=2, j=10: 362167.969 / 0.909\n",
            "Cost / err at iteration i=2, j=20: 216866.766 / 0.854\n",
            "Cost / err at iteration i=2, j=30: 252138.141 / 0.916\n",
            "Cost / err at iteration i=2, j=40: 384537.938 / 0.804\n",
            "Cost / err at iteration i=2, j=50: 256794.781 / 0.914\n",
            "Cost / err at iteration i=2, j=60: 314986.062 / 0.842\n",
            "Cost / err at iteration i=2, j=70: 352394.469 / 0.939\n",
            "Cost / err at iteration i=2, j=80: 329496.750 / 0.923\n",
            "Cost / err at iteration i=2, j=90: 350786.062 / 0.841\n",
            "Cost / err at iteration i=2, j=100: 233916.891 / 0.842\n",
            "Cost / err at iteration i=2, j=110: 280214.062 / 0.859\n",
            "Cost / err at iteration i=2, j=120: 217832.281 / 0.841\n",
            "Cost / err at iteration i=2, j=130: 230036.125 / 0.880\n",
            "Cost / err at iteration i=2, j=140: 320209.125 / 0.894\n",
            "Cost / err at iteration i=3, j=0: 280709.906 / 0.912\n",
            "Cost / err at iteration i=3, j=10: 316188.500 / 0.909\n",
            "Cost / err at iteration i=3, j=20: 215746.969 / 0.889\n",
            "Cost / err at iteration i=3, j=30: 245583.094 / 0.850\n",
            "Cost / err at iteration i=3, j=40: 291859.812 / 0.919\n",
            "Cost / err at iteration i=3, j=50: 270018.875 / 0.928\n",
            "Cost / err at iteration i=3, j=60: 179295.406 / 0.804\n",
            "Cost / err at iteration i=3, j=70: 137961.516 / 0.889\n",
            "Cost / err at iteration i=3, j=80: 135347.594 / 0.841\n",
            "Cost / err at iteration i=3, j=90: 159572.656 / 0.848\n",
            "Cost / err at iteration i=3, j=100: 159182.719 / 0.854\n",
            "Cost / err at iteration i=3, j=110: 166752.797 / 0.939\n",
            "Cost / err at iteration i=3, j=120: 223487.906 / 0.908\n",
            "Cost / err at iteration i=3, j=130: 126952.195 / 0.836\n",
            "Cost / err at iteration i=3, j=140: 164264.859 / 0.804\n",
            "Cost / err at iteration i=4, j=0: 110688.000 / 0.802\n",
            "Cost / err at iteration i=4, j=10: 132919.766 / 0.885\n",
            "Cost / err at iteration i=4, j=20: 212113.562 / 0.801\n",
            "Cost / err at iteration i=4, j=30: 297671.688 / 0.910\n",
            "Cost / err at iteration i=4, j=40: 238719.969 / 0.924\n",
            "Cost / err at iteration i=4, j=50: 248928.906 / 0.911\n",
            "Cost / err at iteration i=4, j=60: 226372.703 / 0.798\n",
            "Cost / err at iteration i=4, j=70: 205509.422 / 0.920\n",
            "Cost / err at iteration i=4, j=80: 149441.953 / 0.806\n",
            "Cost / err at iteration i=4, j=90: 171840.000 / 0.900\n",
            "Cost / err at iteration i=4, j=100: 132202.906 / 0.832\n",
            "Cost / err at iteration i=4, j=110: 108109.672 / 0.845\n",
            "Cost / err at iteration i=4, j=120: 158028.422 / 0.805\n",
            "Cost / err at iteration i=4, j=130: 211317.375 / 0.923\n",
            "Cost / err at iteration i=4, j=140: 96858.078 / 0.898\n",
            "Cost / err at iteration i=5, j=0: 121098.781 / 0.886\n",
            "Cost / err at iteration i=5, j=10: 138397.641 / 0.933\n",
            "Cost / err at iteration i=5, j=20: 120289.172 / 0.852\n",
            "Cost / err at iteration i=5, j=30: 135342.297 / 0.904\n",
            "Cost / err at iteration i=5, j=40: 119373.328 / 0.854\n",
            "Cost / err at iteration i=5, j=50: 118983.391 / 0.886\n",
            "Cost / err at iteration i=5, j=60: 153511.016 / 0.934\n",
            "Cost / err at iteration i=5, j=70: 167748.109 / 0.906\n",
            "Cost / err at iteration i=5, j=80: 153645.062 / 0.908\n",
            "Cost / err at iteration i=5, j=90: 145388.281 / 0.909\n",
            "Cost / err at iteration i=5, j=100: 162000.703 / 0.849\n",
            "Cost / err at iteration i=5, j=110: 136693.766 / 0.877\n",
            "Cost / err at iteration i=5, j=120: 157009.469 / 0.901\n",
            "Cost / err at iteration i=5, j=130: 164784.312 / 0.933\n",
            "Cost / err at iteration i=5, j=140: 122578.688 / 0.799\n",
            "Cost / err at iteration i=6, j=0: 197183.531 / 0.805\n",
            "Cost / err at iteration i=6, j=10: 166622.906 / 0.856\n",
            "Cost / err at iteration i=6, j=20: 135867.000 / 0.902\n",
            "Cost / err at iteration i=6, j=30: 89165.812 / 0.916\n",
            "Cost / err at iteration i=6, j=40: 91189.062 / 0.849\n",
            "Cost / err at iteration i=6, j=50: 90807.656 / 0.805\n",
            "Cost / err at iteration i=6, j=60: 79401.156 / 0.915\n",
            "Cost / err at iteration i=6, j=70: 94380.633 / 0.804\n",
            "Cost / err at iteration i=6, j=80: 94327.438 / 0.906\n",
            "Cost / err at iteration i=6, j=90: 100873.070 / 0.835\n",
            "Cost / err at iteration i=6, j=100: 88858.484 / 0.884\n",
            "Cost / err at iteration i=6, j=110: 98931.898 / 0.840\n",
            "Cost / err at iteration i=6, j=120: 87402.406 / 0.789\n",
            "Cost / err at iteration i=6, j=130: 91342.070 / 0.843\n",
            "Cost / err at iteration i=6, j=140: 78816.125 / 0.840\n",
            "Cost / err at iteration i=7, j=0: 65229.188 / 0.806\n",
            "Cost / err at iteration i=7, j=10: 59972.691 / 0.781\n",
            "Cost / err at iteration i=7, j=20: 61036.887 / 0.836\n",
            "Cost / err at iteration i=7, j=30: 59393.234 / 0.796\n",
            "Cost / err at iteration i=7, j=40: 64097.312 / 0.844\n",
            "Cost / err at iteration i=7, j=50: 89691.688 / 0.876\n",
            "Cost / err at iteration i=7, j=60: 122816.000 / 0.935\n",
            "Cost / err at iteration i=7, j=70: 142344.656 / 0.803\n",
            "Cost / err at iteration i=7, j=80: 242442.156 / 0.924\n",
            "Cost / err at iteration i=7, j=90: 261425.234 / 0.803\n",
            "Cost / err at iteration i=7, j=100: 191829.000 / 0.912\n",
            "Cost / err at iteration i=7, j=110: 202311.781 / 0.940\n",
            "Cost / err at iteration i=7, j=120: 137058.109 / 0.815\n",
            "Cost / err at iteration i=7, j=130: 191501.266 / 0.842\n",
            "Cost / err at iteration i=7, j=140: 146865.094 / 0.869\n",
            "Cost / err at iteration i=8, j=0: 129305.586 / 0.911\n",
            "Cost / err at iteration i=8, j=10: 91183.578 / 0.850\n",
            "Cost / err at iteration i=8, j=20: 91263.500 / 0.843\n",
            "Cost / err at iteration i=8, j=30: 83779.672 / 0.847\n",
            "Cost / err at iteration i=8, j=40: 76642.719 / 0.896\n",
            "Cost / err at iteration i=8, j=50: 63183.484 / 0.882\n",
            "Cost / err at iteration i=8, j=60: 63557.586 / 0.845\n",
            "Cost / err at iteration i=8, j=70: 59652.645 / 0.772\n",
            "Cost / err at iteration i=8, j=80: 60365.234 / 0.777\n",
            "Cost / err at iteration i=8, j=90: 61342.125 / 0.791\n",
            "Cost / err at iteration i=8, j=100: 58928.062 / 0.799\n",
            "Cost / err at iteration i=8, j=110: 59930.188 / 0.802\n",
            "Cost / err at iteration i=8, j=120: 60225.570 / 0.786\n",
            "Cost / err at iteration i=8, j=130: 63087.062 / 0.824\n",
            "Cost / err at iteration i=8, j=140: 90777.539 / 0.804\n",
            "Cost / err at iteration i=9, j=0: 75109.961 / 0.836\n",
            "Cost / err at iteration i=9, j=10: 83417.938 / 0.867\n",
            "Cost / err at iteration i=9, j=20: 109302.188 / 0.880\n",
            "Cost / err at iteration i=9, j=30: 150310.594 / 0.898\n",
            "Cost / err at iteration i=9, j=40: 137534.438 / 0.868\n",
            "Cost / err at iteration i=9, j=50: 166434.109 / 0.893\n",
            "Cost / err at iteration i=9, j=60: 138872.016 / 0.850\n",
            "Cost / err at iteration i=9, j=70: 128446.398 / 0.895\n",
            "Cost / err at iteration i=9, j=80: 180773.828 / 0.841\n",
            "Cost / err at iteration i=9, j=90: 129944.453 / 0.823\n",
            "Cost / err at iteration i=9, j=100: 81703.438 / 0.918\n",
            "Cost / err at iteration i=9, j=110: 88350.461 / 0.806\n",
            "Cost / err at iteration i=9, j=120: 65479.184 / 0.830\n",
            "Cost / err at iteration i=9, j=130: 63404.605 / 0.825\n",
            "Cost / err at iteration i=9, j=140: 63203.508 / 0.754\n",
            "Cost / err at iteration i=10, j=0: 61870.539 / 0.757\n",
            "Cost / err at iteration i=10, j=10: 58710.641 / 0.759\n",
            "Cost / err at iteration i=10, j=20: 57678.250 / 0.747\n",
            "Cost / err at iteration i=10, j=30: 55788.492 / 0.722\n",
            "Cost / err at iteration i=10, j=40: 57838.367 / 0.760\n",
            "Cost / err at iteration i=10, j=50: 67314.438 / 0.814\n",
            "Cost / err at iteration i=10, j=60: 69666.969 / 0.754\n",
            "Cost / err at iteration i=10, j=70: 73846.055 / 0.870\n",
            "Cost / err at iteration i=10, j=80: 87315.109 / 0.786\n",
            "Cost / err at iteration i=10, j=90: 59905.074 / 0.797\n",
            "Cost / err at iteration i=10, j=100: 66780.844 / 0.763\n",
            "Cost / err at iteration i=10, j=110: 58095.758 / 0.738\n",
            "Cost / err at iteration i=10, j=120: 54562.086 / 0.734\n",
            "Cost / err at iteration i=10, j=130: 58442.547 / 0.739\n",
            "Cost / err at iteration i=10, j=140: 69438.859 / 0.778\n",
            "Cost / err at iteration i=11, j=0: 72748.008 / 0.776\n",
            "Cost / err at iteration i=11, j=10: 61836.684 / 0.773\n",
            "Cost / err at iteration i=11, j=20: 57864.414 / 0.727\n",
            "Cost / err at iteration i=11, j=30: 55680.219 / 0.741\n",
            "Cost / err at iteration i=11, j=40: 57314.023 / 0.750\n",
            "Cost / err at iteration i=11, j=50: 60165.043 / 0.749\n",
            "Cost / err at iteration i=11, j=60: 64506.207 / 0.748\n",
            "Cost / err at iteration i=11, j=70: 68290.992 / 0.765\n",
            "Cost / err at iteration i=11, j=80: 61441.773 / 0.801\n",
            "Cost / err at iteration i=11, j=90: 60022.562 / 0.702\n",
            "Cost / err at iteration i=11, j=100: 53570.188 / 0.682\n",
            "Cost / err at iteration i=11, j=110: 50347.648 / 0.666\n",
            "Cost / err at iteration i=11, j=120: 52827.062 / 0.683\n",
            "Cost / err at iteration i=11, j=130: 54495.516 / 0.678\n",
            "Cost / err at iteration i=11, j=140: 57873.688 / 0.690\n",
            "Cost / err at iteration i=12, j=0: 57322.883 / 0.672\n",
            "Cost / err at iteration i=12, j=10: 51057.828 / 0.661\n",
            "Cost / err at iteration i=12, j=20: 46366.984 / 0.599\n",
            "Cost / err at iteration i=12, j=30: 45613.055 / 0.587\n",
            "Cost / err at iteration i=12, j=40: 47226.391 / 0.617\n",
            "Cost / err at iteration i=12, j=50: 45678.047 / 0.586\n",
            "Cost / err at iteration i=12, j=60: 46657.648 / 0.607\n",
            "Cost / err at iteration i=12, j=70: 49024.297 / 0.621\n",
            "Cost / err at iteration i=12, j=80: 43412.906 / 0.558\n",
            "Cost / err at iteration i=12, j=90: 46026.363 / 0.575\n",
            "Cost / err at iteration i=12, j=100: 42706.422 / 0.529\n",
            "Cost / err at iteration i=12, j=110: 41703.402 / 0.521\n",
            "Cost / err at iteration i=12, j=120: 42053.301 / 0.520\n",
            "Cost / err at iteration i=12, j=130: 39783.496 / 0.489\n",
            "Cost / err at iteration i=12, j=140: 40185.988 / 0.497\n",
            "Cost / err at iteration i=13, j=0: 39759.500 / 0.494\n",
            "Cost / err at iteration i=13, j=10: 40613.383 / 0.487\n",
            "Cost / err at iteration i=13, j=20: 38921.961 / 0.492\n",
            "Cost / err at iteration i=13, j=30: 39638.438 / 0.472\n",
            "Cost / err at iteration i=13, j=40: 39051.562 / 0.481\n",
            "Cost / err at iteration i=13, j=50: 37545.484 / 0.446\n",
            "Cost / err at iteration i=13, j=60: 42193.785 / 0.524\n",
            "Cost / err at iteration i=13, j=70: 51557.027 / 0.588\n",
            "Cost / err at iteration i=13, j=80: 57395.871 / 0.575\n",
            "Cost / err at iteration i=13, j=90: 60994.980 / 0.644\n",
            "Cost / err at iteration i=13, j=100: 55424.031 / 0.617\n",
            "Cost / err at iteration i=13, j=110: 51968.246 / 0.561\n",
            "Cost / err at iteration i=13, j=120: 45614.879 / 0.526\n",
            "Cost / err at iteration i=13, j=130: 46361.148 / 0.529\n",
            "Cost / err at iteration i=13, j=140: 51652.078 / 0.513\n",
            "Cost / err at iteration i=14, j=0: 40419.574 / 0.482\n",
            "Cost / err at iteration i=14, j=10: 38943.344 / 0.482\n",
            "Cost / err at iteration i=14, j=20: 36669.855 / 0.426\n",
            "Cost / err at iteration i=14, j=30: 39107.723 / 0.436\n",
            "Cost / err at iteration i=14, j=40: 37752.074 / 0.430\n",
            "Cost / err at iteration i=14, j=50: 39222.625 / 0.458\n",
            "Cost / err at iteration i=14, j=60: 37142.281 / 0.429\n",
            "Cost / err at iteration i=14, j=70: 36803.086 / 0.428\n",
            "Cost / err at iteration i=14, j=80: 35280.750 / 0.402\n",
            "Cost / err at iteration i=14, j=90: 35885.680 / 0.409\n",
            "Cost / err at iteration i=14, j=100: 37018.211 / 0.424\n",
            "Cost / err at iteration i=14, j=110: 36447.414 / 0.411\n",
            "Cost / err at iteration i=14, j=120: 36587.102 / 0.410\n",
            "Cost / err at iteration i=14, j=130: 37456.582 / 0.443\n",
            "Cost / err at iteration i=14, j=140: 39824.879 / 0.465\n",
            "Cost / err at iteration i=15, j=0: 45508.426 / 0.471\n",
            "Cost / err at iteration i=15, j=10: 43618.188 / 0.479\n",
            "Cost / err at iteration i=15, j=20: 39558.414 / 0.475\n",
            "Cost / err at iteration i=15, j=30: 35210.203 / 0.396\n",
            "Cost / err at iteration i=15, j=40: 37329.383 / 0.421\n",
            "Cost / err at iteration i=15, j=50: 34569.273 / 0.392\n",
            "Cost / err at iteration i=15, j=60: 34733.367 / 0.398\n",
            "Cost / err at iteration i=15, j=70: 35930.098 / 0.420\n",
            "Cost / err at iteration i=15, j=80: 36346.121 / 0.417\n",
            "Cost / err at iteration i=15, j=90: 33629.715 / 0.374\n",
            "Cost / err at iteration i=15, j=100: 35903.094 / 0.407\n",
            "Cost / err at iteration i=15, j=110: 33746.961 / 0.382\n",
            "Cost / err at iteration i=15, j=120: 35372.859 / 0.403\n",
            "Cost / err at iteration i=15, j=130: 34153.625 / 0.393\n",
            "Cost / err at iteration i=15, j=140: 35161.230 / 0.393\n",
            "Cost / err at iteration i=16, j=0: 35326.805 / 0.407\n",
            "Cost / err at iteration i=16, j=10: 33541.738 / 0.378\n",
            "Cost / err at iteration i=16, j=20: 33653.332 / 0.390\n",
            "Cost / err at iteration i=16, j=30: 35113.121 / 0.406\n",
            "Cost / err at iteration i=16, j=40: 33754.227 / 0.389\n",
            "Cost / err at iteration i=16, j=50: 35785.195 / 0.413\n",
            "Cost / err at iteration i=16, j=60: 34723.523 / 0.383\n",
            "Cost / err at iteration i=16, j=70: 33301.531 / 0.370\n",
            "Cost / err at iteration i=16, j=80: 33784.938 / 0.386\n",
            "Cost / err at iteration i=16, j=90: 34418.289 / 0.382\n",
            "Cost / err at iteration i=16, j=100: 34038.574 / 0.388\n",
            "Cost / err at iteration i=16, j=110: 32609.342 / 0.357\n",
            "Cost / err at iteration i=16, j=120: 33853.801 / 0.378\n",
            "Cost / err at iteration i=16, j=130: 33558.746 / 0.382\n",
            "Cost / err at iteration i=16, j=140: 35205.777 / 0.401\n",
            "Cost / err at iteration i=17, j=0: 37224.906 / 0.396\n",
            "Cost / err at iteration i=17, j=10: 33185.367 / 0.375\n",
            "Cost / err at iteration i=17, j=20: 35124.355 / 0.393\n",
            "Cost / err at iteration i=17, j=30: 32787.848 / 0.369\n",
            "Cost / err at iteration i=17, j=40: 35002.312 / 0.389\n",
            "Cost / err at iteration i=17, j=50: 34161.219 / 0.379\n",
            "Cost / err at iteration i=17, j=60: 35214.879 / 0.392\n",
            "Cost / err at iteration i=17, j=70: 34813.719 / 0.384\n",
            "Cost / err at iteration i=17, j=80: 33424.844 / 0.365\n",
            "Cost / err at iteration i=17, j=90: 32205.271 / 0.361\n",
            "Cost / err at iteration i=17, j=100: 32414.668 / 0.367\n",
            "Cost / err at iteration i=17, j=110: 32002.393 / 0.359\n",
            "Cost / err at iteration i=17, j=120: 30939.441 / 0.343\n",
            "Cost / err at iteration i=17, j=130: 31980.807 / 0.359\n",
            "Cost / err at iteration i=17, j=140: 35118.473 / 0.399\n",
            "Cost / err at iteration i=18, j=0: 33193.141 / 0.365\n",
            "Cost / err at iteration i=18, j=10: 32065.201 / 0.353\n",
            "Cost / err at iteration i=18, j=20: 32217.420 / 0.356\n",
            "Cost / err at iteration i=18, j=30: 31351.688 / 0.355\n",
            "Cost / err at iteration i=18, j=40: 32846.391 / 0.366\n",
            "Cost / err at iteration i=18, j=50: 37731.086 / 0.405\n",
            "Cost / err at iteration i=18, j=60: 38131.730 / 0.436\n",
            "Cost / err at iteration i=18, j=70: 34224.000 / 0.383\n",
            "Cost / err at iteration i=18, j=80: 35373.898 / 0.404\n",
            "Cost / err at iteration i=18, j=90: 34361.641 / 0.387\n",
            "Cost / err at iteration i=18, j=100: 31961.660 / 0.365\n",
            "Cost / err at iteration i=18, j=110: 32078.625 / 0.350\n",
            "Cost / err at iteration i=18, j=120: 30606.873 / 0.336\n",
            "Cost / err at iteration i=18, j=130: 30275.957 / 0.334\n",
            "Cost / err at iteration i=18, j=140: 29981.062 / 0.327\n",
            "Cost / err at iteration i=19, j=0: 30402.359 / 0.339\n",
            "Cost / err at iteration i=19, j=10: 29771.736 / 0.331\n",
            "Cost / err at iteration i=19, j=20: 30929.359 / 0.340\n",
            "Cost / err at iteration i=19, j=30: 29640.516 / 0.333\n",
            "Cost / err at iteration i=19, j=40: 32205.699 / 0.355\n",
            "Cost / err at iteration i=19, j=50: 32515.057 / 0.359\n",
            "Cost / err at iteration i=19, j=60: 30387.859 / 0.339\n",
            "Cost / err at iteration i=19, j=70: 31759.580 / 0.363\n",
            "Cost / err at iteration i=19, j=80: 30974.953 / 0.346\n",
            "Cost / err at iteration i=19, j=90: 33273.973 / 0.386\n",
            "Cost / err at iteration i=19, j=100: 30475.410 / 0.347\n",
            "Cost / err at iteration i=19, j=110: 29031.879 / 0.317\n",
            "Cost / err at iteration i=19, j=120: 29108.219 / 0.320\n",
            "Cost / err at iteration i=19, j=130: 29012.781 / 0.327\n",
            "Cost / err at iteration i=19, j=140: 29372.678 / 0.327\n",
            "Elapsed time:  0:02:54.555706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKrE/weqkqSq+mX+JQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNDz2Ym9FNgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}